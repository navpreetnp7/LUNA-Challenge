{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from collections import namedtuple\n",
    "import copy\n",
    "import csv\n",
    "import functools\n",
    "import glob\n",
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import logging.handlers\n",
    "\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.setLevel(logging.INFO)\n",
    "\n",
    "# Some libraries attempt to add their own root logger handlers. This is\n",
    "# annoying and so we get rid of them.\n",
    "for handler in list(root_logger.handlers):\n",
    "    root_logger.removeHandler(handler)\n",
    "\n",
    "logfmt_str = \"%(asctime)s %(levelname)-8s pid:%(process)d %(name)s:%(lineno)03d:%(funcName)s %(message)s\"\n",
    "formatter = logging.Formatter(logfmt_str)\n",
    "\n",
    "streamHandler = logging.StreamHandler()\n",
    "streamHandler.setFormatter(formatter)\n",
    "streamHandler.setLevel(logging.DEBUG)\n",
    "\n",
    "root_logger.addHandler(streamHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.WARN)\n",
    "# log.setLevel(logging.INFO)\n",
    "log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diskcache import FanoutCache, Disk\n",
    "from diskcache.core import BytesType, MODE_BINARY, BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCache(scope_str):\n",
    "    return FanoutCache('../data-luna/data-unversioned/cache/' + scope_str,\n",
    "                       disk=GzipDisk,\n",
    "                       shards=64,\n",
    "                       timeout=1,\n",
    "                       size_limit=3e11,\n",
    "                       # disk_min_file_size=2**20,\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GzipDisk(Disk):\n",
    "    def store(self, value, read, key=None):\n",
    "        \"\"\"\n",
    "        Override from base class diskcache.Disk.\n",
    "        Chunking is due to needing to work on pythons < 2.7.13:\n",
    "        - Issue #27130: In the \"zlib\" module, fix handling of large buffers\n",
    "          (typically 2 or 4 GiB).  Previously, inputs were limited to 2 GiB, and\n",
    "          compression and decompression operations did not properly handle results of\n",
    "          2 or 4 GiB.\n",
    "        :param value: value to convert\n",
    "        :param bool read: True when value is file-like object\n",
    "        :return: (size, mode, filename, value) tuple for Cache table\n",
    "        \"\"\"\n",
    "        # pylint: disable=unidiomatic-typecheck\n",
    "        if type(value) is BytesType:\n",
    "            if read:\n",
    "                value = value.read()\n",
    "                read = False\n",
    "\n",
    "            str_io = BytesIO()\n",
    "            gz_file = gzip.GzipFile(mode='wb', compresslevel=1, fileobj=str_io)\n",
    "\n",
    "            for offset in range(0, len(value), 2**30):\n",
    "                gz_file.write(value[offset:offset+2**30])\n",
    "            gz_file.close()\n",
    "\n",
    "            value = str_io.getvalue()\n",
    "\n",
    "        return super(GzipDisk, self).store(value, read)\n",
    "\n",
    "\n",
    "    def fetch(self, mode, filename, value, read):\n",
    "        \"\"\"\n",
    "        Override from base class diskcache.Disk.\n",
    "        Chunking is due to needing to work on pythons < 2.7.13:\n",
    "        - Issue #27130: In the \"zlib\" module, fix handling of large buffers\n",
    "          (typically 2 or 4 GiB).  Previously, inputs were limited to 2 GiB, and\n",
    "          compression and decompression operations did not properly handle results of\n",
    "          2 or 4 GiB.\n",
    "        :param int mode: value mode raw, binary, text, or pickle\n",
    "        :param str filename: filename of corresponding value\n",
    "        :param value: database value\n",
    "        :param bool read: when True, return an open file handle\n",
    "        :return: corresponding Python value\n",
    "        \"\"\"\n",
    "        value = super(GzipDisk, self).fetch(mode, filename, value, read)\n",
    "\n",
    "        if mode == MODE_BINARY:\n",
    "            str_io = BytesIO(value)\n",
    "            gz_file = gzip.GzipFile(mode='rb', fileobj=str_io)\n",
    "            read_csio = BytesIO()\n",
    "\n",
    "            while True:\n",
    "                uncompressed_data = gz_file.read(2**30)\n",
    "                if uncompressed_data:\n",
    "                    read_csio.write(uncompressed_data)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            value = read_csio.getvalue()\n",
    "\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CandidateInfoTuple = namedtuple(\n",
    "    'CandidateInfoTuple',\n",
    "    'isNodule_bool,diameter_mm,series_uid,center_xyz'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrcTuple = collections.namedtuple('IrcTuple', ['index', 'row', 'col'])\n",
    "XyzTuple = collections.namedtuple('XyzTuple', ['x', 'y', 'z'])\n",
    "\n",
    "def irc2xyz(coord_irc, origin_xyz, vxSize_xyz, direction_a):\n",
    "    cri_a = np.array(coord_irc)[::-1]\n",
    "    origin_a = np.array(origin_xyz)\n",
    "    vxSize_a = np.array(vxSize_xyz)\n",
    "    coords_xyz = (direction_a @ (cri_a * vxSize_a)) + origin_a\n",
    "    # coords_xyz = (direction_a @ (idx * vxSize_a)) + origin_a\n",
    "    return XyzTuple(*coords_xyz)\n",
    "\n",
    "def xyz2irc(coord_xyz, origin_xyz, vxSize_xyz, direction_a):\n",
    "    origin_a = np.array(origin_xyz)\n",
    "    vxSize_a = np.array(vxSize_xyz)\n",
    "    coord_a = np.array(coord_xyz)\n",
    "    cri_a = ((coord_a - origin_a) @ np.linalg.inv(direction_a)) / vxSize_a\n",
    "    cri_a = np.round(cri_a)\n",
    "    return IrcTuple(int(cri_a[2]), int(cri_a[1]), int(cri_a[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(1)\n",
    "def getCandidateInfoList(requireOnDisk_bool=True):\n",
    "    mhd_list = glob.glob('../data-luna/subset*/*.mhd')\n",
    "    presentOnDisk_set = {os.path.split(p)[-1][:-4] for p in mhd_list}\n",
    "    \n",
    "    \n",
    "    diameter_dict = {}\n",
    "    with open('../data-luna/annotations.csv', \"r\") as f:\n",
    "        for row in list(csv.reader(f))[1:]:\n",
    "            series_uid = row[0]\n",
    "            annotationCenter_xyz = tuple([float(x) for x in row[1:4]])\n",
    "            annotationDiameter_mm = float(row[4])\n",
    "\n",
    "            diameter_dict.setdefault(series_uid, []).append(\n",
    "                (annotationCenter_xyz, annotationDiameter_mm)\n",
    "            )\n",
    "            \n",
    "    \n",
    "    candidateInfo_list = []\n",
    "    with open('../data-luna/candidates.csv', \"r\") as f:\n",
    "        for row in list(csv.reader(f))[1:]:\n",
    "            series_uid = row[0]\n",
    "\n",
    "            if series_uid not in presentOnDisk_set and requireOnDisk_bool:\n",
    "                continue\n",
    "\n",
    "            isNodule_bool = bool(int(row[4]))\n",
    "            candidateCenter_xyz = tuple([float(x) for x in row[1:4]])\n",
    "\n",
    "            candidateDiameter_mm = 0.0\n",
    "            for annotation_tup in diameter_dict.get(series_uid, []):\n",
    "                annotationCenter_xyz, annotationDiameter_mm = annotation_tup\n",
    "                for i in range(3):\n",
    "                    delta_mm = abs(candidateCenter_xyz[i] - annotationCenter_xyz[i])\n",
    "                    if delta_mm > annotationDiameter_mm / 4:\n",
    "                        break\n",
    "                else:\n",
    "                    candidateDiameter_mm = annotationDiameter_mm\n",
    "                    break\n",
    "\n",
    "            candidateInfo_list.append(CandidateInfoTuple(\n",
    "                isNodule_bool,\n",
    "                candidateDiameter_mm,\n",
    "                series_uid,\n",
    "                candidateCenter_xyz,\n",
    "            ))\n",
    "\n",
    "    candidateInfo_list.sort(reverse=True)\n",
    "    return candidateInfo_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "class Ct:\n",
    "    def __init__(self, series_uid):\n",
    "        mhd_path = glob.glob(\n",
    "            '../data-luna/subset*/{}.mhd'.format(series_uid)\n",
    "        )[0]\n",
    "\n",
    "        ct_mhd = sitk.ReadImage(mhd_path)\n",
    "        ct_a = np.array(sitk.GetArrayFromImage(ct_mhd), dtype=np.float32)\n",
    "        \n",
    "        ct_a.clip(-1000, 1000, ct_a)\n",
    "        self.series_uid = series_uid\n",
    "        self.hu_a = ct_a\n",
    "        \n",
    "        self.origin_xyz = XyzTuple(*ct_mhd.GetOrigin())\n",
    "        self.vxSize_xyz = XyzTuple(*ct_mhd.GetSpacing())\n",
    "        self.direction_a = np.array(ct_mhd.GetDirection()).reshape(3, 3)\n",
    "        \n",
    "    def getRawCandidate(self, center_xyz, width_irc):\n",
    "        center_irc = xyz2irc(\n",
    "            center_xyz,\n",
    "            self.origin_xyz,\n",
    "            self.vxSize_xyz,\n",
    "            self.direction_a,\n",
    "        )\n",
    "\n",
    "        slice_list = []\n",
    "        for axis, center_val in enumerate(center_irc):\n",
    "            start_ndx = int(round(center_val - width_irc[axis]/2))\n",
    "            end_ndx = int(start_ndx + width_irc[axis])\n",
    "\n",
    "            assert center_val >= 0 and center_val < self.hu_a.shape[axis], repr([self.series_uid, center_xyz, self.origin_xyz, self.vxSize_xyz, center_irc, axis])\n",
    "\n",
    "            if start_ndx < 0: # Crop outside of CT array\n",
    "                start_ndx = 0\n",
    "                end_ndx = int(width_irc[axis])\n",
    "\n",
    "            if end_ndx > self.hu_a.shape[axis]: # Crop outside of CT array\n",
    "                end_ndx = self.hu_a.shape[axis]\n",
    "                start_ndx = int(self.hu_a.shape[axis] - width_irc[axis])\n",
    "\n",
    "            slice_list.append(slice(start_ndx, end_ndx))\n",
    "\n",
    "        ct_chunk = self.hu_a[tuple(slice_list)]\n",
    "\n",
    "        return ct_chunk, center_irc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhd_path = glob.glob(\n",
    "            '../data-luna/subset0/{}.mhd'.format('1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260')\n",
    "        )[0]\n",
    "ct_mhd = sitk.ReadImage(mhd_path)\n",
    "ct_a = np.array(sitk.GetArrayFromImage(ct_mhd), dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunaModel(nn.Module):\n",
    "    def __init__(self, in_channels=1, conv_channels=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tail_batchnorm = nn.BatchNorm3d(1)\n",
    "\n",
    "        self.block1 = LunaBlock(in_channels, conv_channels)\n",
    "        self.block2 = LunaBlock(conv_channels, conv_channels * 2)\n",
    "        self.block3 = LunaBlock(conv_channels * 2, conv_channels * 4)\n",
    "        self.block4 = LunaBlock(conv_channels * 4, conv_channels * 8)\n",
    "\n",
    "        self.head_linear = nn.Linear(1152, 2)\n",
    "        self.head_softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    # see also https://github.com/pytorch/pytorch/issues/18182\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if type(m) in {\n",
    "                nn.Linear,\n",
    "                nn.Conv3d,\n",
    "                nn.Conv2d,\n",
    "                nn.ConvTranspose2d,\n",
    "                nn.ConvTranspose3d,\n",
    "            }:\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight.data, a=0, mode='fan_out', nonlinearity='relu',\n",
    "                )\n",
    "                if m.bias is not None:\n",
    "                    fan_in, fan_out = \\\n",
    "                        nn.init._calculate_fan_in_and_fan_out(m.weight.data)\n",
    "                    bound = 1 / math.sqrt(fan_out)\n",
    "                    nn.init.normal_(m.bias, -bound, bound)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        bn_output = self.tail_batchnorm(input_batch)\n",
    "\n",
    "        block_out = self.block1(bn_output)\n",
    "        block_out = self.block2(block_out)\n",
    "        block_out = self.block3(block_out)\n",
    "        block_out = self.block4(block_out)\n",
    "\n",
    "        conv_flat = block_out.view(\n",
    "            block_out.size(0),\n",
    "            -1,\n",
    "        )\n",
    "        linear_output = self.head_linear(conv_flat)\n",
    "\n",
    "        return linear_output, self.head_softmax(linear_output)\n",
    "\n",
    "\n",
    "class LunaBlock(nn.Module):\n",
    "    def __init__(self, in_channels, conv_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(\n",
    "            in_channels, conv_channels, kernel_size=3, padding=1, bias=True,\n",
    "        )\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(\n",
    "            conv_channels, conv_channels, kernel_size=3, padding=1, bias=True,\n",
    "        )\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.maxpool = nn.MaxPool3d(2, 2)\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        block_out = self.conv1(input_batch)\n",
    "        block_out = self.relu1(block_out)\n",
    "        block_out = self.conv2(block_out)\n",
    "        block_out = self.relu2(block_out)\n",
    "\n",
    "        return self.maxpool(block_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
